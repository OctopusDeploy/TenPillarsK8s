<h1><a id="chapter3">Seamless deployments</a></h1>
<p>
    Reducing or eliminating downtime during a deployment becomes increasingly critical as the number and frequency of deployments increases. There are a number of common deployment strategies to reduce downtime or ensure our applications remain available throughout a deployment, resulting in seamless deployments. Given the range of high quality networking solutions that are available in the Kubernetes ecosystem, Kubernetes deployments are well placed to take advantage of these strategies.
</p>
<p>
    In this chapter we'll look at the common deployment strategies and provide examples of how these strategies can be realized with an Octopus deployment.
</p>
<h2>Dealing with databases during deployments</h2>
<p>
    No discussion on seamless deployments can begin without first addressing the issue of database updates.
</p>
<p>
    A fundamental aspect of most seamless deployment strategies involves running two versions of your application side by side, if only for a short period of time. If both versions of the application access a shared database, then any updates to the database schema and data must be compatible with both application versions. This is referred to as backward and forward compatibility.
</p>
<p>
    However, backward and forward compatibility is not trivial to implement. In the presentation Update your Database Schema with Zero Downtime Migrations available at <a href="https://www.youtube.com/watch?v=3mj6Ni7sRN4">https://www.youtube.com/watch?v=3mj6Ni7sRN4</a> (based on chapter 3 of the book Migrating to Microservice Databases available at <a href="https://developers.redhat.com/books/migrating-microservice-databases-relational-monolith-distributed-data">https://developers.redhat.com/books/migrating-microservice-databases-relational-monolith-distributed-data</a>), Edison Yanaga walks through the process of renaming a single column in a database. It involves six incremental updates to the database and application code, and all six versions to be deployed sequentially.
</p>
<p>
    Needless to say, seamless deployments involving databases require a great deal of planning, many small steps to roll out the changes, and tight coordination between the database and application code.
</p>
<p>
    We won't dive into the specifics of how to engineer an application with forward and backward database compatibility in this book. This is an application design concern, and whether or not an application supports forward and backward database compatibility is already determined when it is to be deployed. The deployment strategy does need to take into account whether an application supports running two versions side by side, but can not add this functionality if it isn't already built into the application.
</p>
<h2>Common deployment strategies</h2>
<p>
    There are multiple strategies to manage a cutover between an existing deployment and a new one.
</p>
<h3>Recreate</h3>
<p>
    The recreate strategy does not provide a seamless deployment, but is included here as it is the default option for most deployment processes. This strategy involves either removing the existing deployment and deploying the new version, or deploying the new version over the top of the existing deployment.
</p>
<p>
    Both options result in downtime during the period between the existing version being stopped or removed and the new version being started. However, because the existing and new versions are not run concurrently, database upgrades can be applied as needed with no backward and forward compatibility requirements.
</p>
<h3>Rolling updates</h3>
<p>
    The rolling update strategy involves incrementally updating instances of the current deployment with the new deployment. This strategy ensures there is always at least one instance of the current or new deployment available during the rollout. This requires that any shared database must maintain backward and forward compatibility.
</p>
<h3>Canary deployments</h3>
<p>
    The canary deployment strategy is similar to the rolling update strategy in that both incrementally expose more end users to the new deployment. The difference is that the decision to progress the rollout in a canary deployment is either made automatically by a system monitoring metrics and logs to ensure the new deployment is performing as expected, or manually by a human.
</p>
<p>
    Canary deployments also have the option to halt the rollout and revert back to the existing deployment if a problem is discovered.
</p>
<h3>Blue/green deployments</h3>
<p>
    The blue/green strategy involves deploying the new version (referred to as the green version) alongside the current version (referred to as the blue version), without exposing the green version to any traffic. Once the green version is deployed and verified, traffic is cutover from the blue to the green version. When the blue version is no longer used, it can be removed.
</p>
<p>
    Any database changes deployed by the green version must maintain backward and forward compatibility, because even if the green version is not serving traffic, the blue version will be exposed to the database changes.
</p>
<h3>Session draining</h3>
<p>
    The session draining strategy is used when applications maintain states tied to a particular application version.
</p>
<p>
    This strategy is similar to the blue/green strategy in that both will deploy the new version alongside the current version, and run both side by side. Unlike the blue/green strategy, which will cut all traffic over to the new deployment in a single step, the session draining strategy will direct new sessions to the new deployment, while the existing deployment serves traffic to existing sessions.
</p>
<p>
    After the old sessions have expired, the existing deployment can be deleted.
</p>
<p>
    Because the current and new deployments run side by side, any database changes must maintain backward and forward compatibility.
</p>
<p>
    Session draining was particularly important for older server side stateful web applications. This style of application has largely gone out of style, in large part because it made it difficult to manage with PaaS offerings that often treated any individual application instance as ephemeral. This book won't cover session draining in Kubernetes clusters.
</p>
<h3>Feature flags</h3>
<p>
    The feature flag strategy involves building functionality into a new application version, and then exposing or hiding the feature for select end users outside of the deployment process.
</p>
<p>
    In practice, the deployment of a new application version with flaggable features will be performed with one of the strategies above, so the feature flag strategy is a complement to those other strategies.
</p>
<p>
    A more limited approach to feature flags may be to enable or disable features for an entire deployment. For example, a new feature may be exposed to testers in non-production environments, but be disabled entirely when deployed to production. This broader approach is something that can be managed as part of a deployment.
</p>
<h3>Feature branch</h3>
<p>
    The feature branch strategy allows developers to deploy an application version with changes they are currently implementing, usually in a non-production environment, alongside the main deployment.
</p>
<p>
    It may not be necessary to maintain database backward and forward compatibility with feature branch deployments. Because feature branches are for testing and tend to be short-lived, it may be acceptable that each feature branch deployment has access to its own test database.
</p>
<h2>Seamless {{ site.platform }} deployments</h2>
<p>
    Kubernetes has out of the box support for the rolling deployment strategy for pods managed by a deployment, statefulset, or daemonset. Kubernetes also supports the recreate strategy for pods managed by a deployment. This gives us tick box support to utilize these strategies while deploying our applications.
</p>
<p>
    More advanced deployment strategies like blue/green or canary will often require some planing during a deployment, or rely on third party networking tools to provide fine grained control over which services respond to a request.
</p>
<p>
    Kubernetes has no concept of feature branch deployments. However, with some sensible naming patterns it is possible to implement feature branch deployments in a relatively straightforward manner.
</p>
<h3>Rolling and recreate deployments</h3>
<p>
    Although we didn't call it out in <a href="chapter1">chapter 1</a>, the deployment process we created is already configured to perform a rolling update. All Kubernetes deployment resources will be updated using either a rolling or recreate strategy, and the rolling update strategy was selected for us by default.
</p>
<p>
    To make either strategy meaningful we need to deploy more than one pod, so open the <b>Random Quotes - Frontend</b> project, select the <b>Deploy Kubernetes containers</b> step that deploys the frontend application, and then change the replicas count to 5. This will result in 5 pods being created with the frontend web application, with traffic distributed between them by the service.
</p>
<p>
    Deploy the <b>Random Quotes - Frontend</b> project to the <b>Development</b> environment with the new replica count to populate the cluster with the new pods.
</p>
<p>
    Now redeploy the <b>Random Quotes - Frontend</b> project to the <b>Development</b> environment. When Octopus presents the package versions, expand the packages section, click the <b>SELECT VERSION</b> button next to the <b>octopussamples/randomquotesjava</b> package, tick the <b>Pre-release packages</b> option, and select the <b>0.1.9-purpleheader</b> version. This version of the image replaces the background color of the header displayed by the web frontend. Click the <b>OK</b> button to select the new version.
</p>
<p class="note">
    Although Docker tags have no concept of a pre-release, Octopus treats tags like <b>0.1.9-purpleheader</b> as a prerelease version, with the identifier <b>purpleheader</b> indicating this is a pre-release.
</p>
<p>
    The log files generated during the deployment show entries like <b>Waiting for deployment "webapp" rollout to finish: 4 out of 5 new replicas have been updated...</b>, followed by entries like <b>Waiting for deployment "webapp" rollout to finish: 2 old replicas are pending termination...</b>. This indicates that Kubernetes is deploying pods with the new image before deleting pods with the old image.
</p>
<p>
    The diagram below shows how a rolling update strategy progresses, with old pods progressively deleted and replaced with new pods:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/rolling-deployment.png"/></div>
<p>
    Go back to the deployment process for the <b>Random Quotes - Frontend</b> project, select the <b>Deploy Kubernetes containers</b> step that deploys the frontend application, expand the <b>Deployment Strategy</b> section, and select the <b>Recreate deployments</b> option. Save the changes and redeploy the project to the <b>Development</b> environment.
</p>
<p>
    Notice now the log files now only have messages like <b>Waiting for deployment "webapp" rollout to finish: 0 out of 5 new replicas have been updated...</b>, with the replica count increasing until all pods have been deployed. This indicates that the old pods were removed before any new pods were deployed.
</p>
<p>
    The diagram below shows how a recreate update strategy progresses, where all old pods are first deleted, and new pods are then deployed:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/recreate-deployment.png"/></div>
<h3>Blue/green deployments</h3>
<p>
    Unlike the rolling and recreate strategies, blue/green deployments are not natively supported by Kubernetes. However, Octopus does provide the ability to perform blue/green deployments by orchestrating the various Kubernetes resources for you.
</p>
<p>
    Open the <b>Random Quotes - Frontend</b> project, select the <b>Deploy Kubernetes containers</b> step that deploys the frontend application, expand the <b>Deployment Strategy</b> section, and select the <b>Blue/Green deployments</b> option. Save the changes and deploy the project to the <b>Development</b> environment.
</p>
<p>
    Notice that the logs container entries like <b>deployment.apps/webapp-deployments-101 created</b>. Of particular note is that the name of the deployment is made up of the name that was entered into the step, which was <b>webapp</b>, and a suffix like <b>-deployments-101</b>.
</p>
<p>
    This is a crucial aspect of cloud deployments. To have the blue and green stacks coexist side by side in the cluster, resources like the Kubernetes deployment must have unique names. Octopus ensures this by appending the deployment ID to the end of the deployment name. This ensures each deployment orchestrated by Octopus generates a unique Kubernetes deployment resource.
</p>
<p>
    Note though that not all resources created by this step have a unique name. There is only one service created as part of a blue/green deployment, so it retains the name of <b>webapp</b>.
</p>
<p class="note">
    The service and ingress resources created by the step do not have the deployment ID appended to their names. The deployment/statefulset/daemonset, secret, configmap, and custom resources all have the deployment ID appended to their names during a blue/green deployment.
</p>
<p>
    After the first blue/green deployment, our cluster looks like this. We have a shared service pointing to a uniquely named deployment. The deployment was successful, so the new deployment becomes the green stack:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/bluegreen1.png"/></div>
<p>
    Now lets deploy the project to the <b>Development</b> environment again. Notice now the logs container entries like <b>deployment.apps/webapp-deployments-102 created</b>. This is a new deployment, so the suffix appended to the deployment resource has been updated.
</p>
<p>
    As the new deployment resource is spun on in the cluster, the state of the cluster looks like this. The new deployment, considered to be the blue stack, is created but not yet receiving traffic:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/bluegreen2.png"/></div>
<p>
    Once the new deployment resource has passed all of its health checks and is considered fully available, the service is updated to direct traffic to the it:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/bluegreen3.png"/></div>
<p>
    The resources in the green stack are now deleted:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/bluegreen4.png"/></div>
<p>
    With the deployment process now done, the resources from the blue stack are now considered to be the green stack:
</p>
<div><img alt="Octopus environments" src="images/kubernetes/bluegreen5.png"/></div>